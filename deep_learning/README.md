# Deep Learning para SegmentaÃ§Ã£o de NÃ³dulos Pulmonares

Esta pasta contÃ©m a **Fase 2** do projeto PulmoSeg: implementaÃ§Ã£o de arquiteturas de Deep Learning para superar as limitaÃ§Ãµes das tÃ©cnicas clÃ¡ssicas.

---

## ğŸ¯ Objetivo

Desenvolver e comparar mÃºltiplas arquiteturas de Deep Learning para segmentaÃ§Ã£o precisa de nÃ³dulos pulmonares, visando alcanÃ§ar **Dice Score > 0.70** (vs 0.023 das tÃ©cnicas clÃ¡ssicas).

---

## ğŸ—ï¸ Arquiteturas Implementadas

### 1. U-Net 2D (Baseline DL)

**CaracterÃ­sticas:**
- Arquitetura encoder-decoder clÃ¡ssica para segmentaÃ§Ã£o mÃ©dica
- Encoder prÃ©-treinado: ResNet34 (ImageNet)
- Skip connections entre encoder e decoder
- **Dice esperado**: 0.65-0.75

### 2. Attention U-Net (MAnet)

**CaracterÃ­sticas:**
- Attention gates para focar em regiÃµes relevantes
- SupressÃ£o de features irrelevantes
- Melhoria esperada: +10-15% vs U-Net vanilla
- **Dice esperado**: 0.70-0.80

### 3. U-Net++

**CaracterÃ­sticas:**
- Nested skip connections (dense connections)
- Re-designed skip pathways
- Estado da arte em segmentaÃ§Ã£o mÃ©dica
- **Dice esperado**: 0.75-0.85

---

## ğŸ”§ Pipeline de Treinamento

### 1. PreparaÃ§Ã£o de Dados

**Split do Dataset:**
- **70% Treino** (â‰ˆ600 pacientes)
- **15% ValidaÃ§Ã£o** (â‰ˆ130 pacientes)
- **15% Teste** (â‰ˆ130 pacientes)

**Importante:** Split por **pacientes** (nÃ£o por slices) para evitar data leakage.

**Ground Truth:** MÃ¡scara de consenso (â‰¥2 radiologistas concordam)

### 2. Data Augmentation

Pipeline conservador otimizado para imagens mÃ©dicas:

| TransformaÃ§Ã£o | ConfiguraÃ§Ã£o | Probabilidade |
|---------------|--------------|---------------|
| **RotaÃ§Ã£o** | Â±15Â° | 70% |
| **Flip Horizontal** | - | 50% |
| **Flip Vertical** | - | 50% |
| **Escala** | 0.9-1.1 | 70% |
| **Brilho/Contraste** | Â±20% | 50% |
| **Elastic Deformation** | Î±=50, Ïƒ=8 | 30% |
| **Grid Distortion** | - | 20% |
| **Optical Distortion** | - | 20% |

### 3. ConfiguraÃ§Ãµes de Treinamento

```python
# Otimizado para MacBook M2 16GB
BATCH_SIZE = 8
NUM_EPOCHS = 50
LEARNING_RATE = 1e-4
OPTIMIZER = AdamW (weight_decay=1e-5)

# Loss Function
LOSS = Combined (0.5 * Dice + 0.5 * BCE)

# RegularizaÃ§Ã£o
EARLY_STOPPING_PATIENCE = 15
GRADIENT_CLIPPING = 1.0
LR_SCHEDULER = ReduceLROnPlateau

# Hardware
DEVICE = Apple MPS (Metal Performance Shaders)
MIXED_PRECISION = True (FP16)
```

### 4. MÃ©tricas de AvaliaÃ§Ã£o

- **Dice Coefficient** (F1-Score para segmentaÃ§Ã£o)
- **IoU** (Intersection over Union)
- **Precision** (Positive Predictive Value)
- **Recall** (Sensitivity)

---

## ğŸ“ Estrutura de Arquivos

```
deep_learning/
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ train.py                     # Script principal de treinamento
â”œâ”€â”€ evaluate.py                  # AvaliaÃ§Ã£o no test set
â”œâ”€â”€ compare_models.py            # ComparaÃ§Ã£o DL vs ClÃ¡ssico
â”œâ”€â”€ visualize_predictions.py     # Visualizar prediÃ§Ãµes
â”œâ”€â”€ requirements-dl.txt          # DependÃªncias PyTorch
â””â”€â”€ src/
    â”œâ”€â”€ config.py                # ConfiguraÃ§Ãµes centralizadas
    â”œâ”€â”€ dataset.py               # PyTorch DataLoader customizado
    â”œâ”€â”€ augmentation.py          # Pipeline de augmentation
    â”œâ”€â”€ losses.py                # Dice, BCE, Focal, Combined
    â”œâ”€â”€ metrics.py               # Dice, IoU, Precision, Recall
    â”œâ”€â”€ trainer.py               # Training loop + early stopping
    â””â”€â”€ models/
        â””â”€â”€ unet.py              # U-Net, Attention U-Net, U-Net++
```

**Gerados apÃ³s treinamento:**

```
checkpoints/
â””â”€â”€ {experiment_name}/
    â”œâ”€â”€ best.pth                 # Melhor modelo (maior Dice val)
    â””â”€â”€ last.pth                 # Ãšltimo checkpoint

runs/
â””â”€â”€ {experiment_name}/           # TensorBoard logs
    â””â”€â”€ events.out.tfevents.*

results/
â””â”€â”€ dl_models/
    â”œâ”€â”€ visualizations/          # PrediÃ§Ãµes visualizadas
    â””â”€â”€ comparison_report.md     # RelatÃ³rio comparativo
```

---

## ğŸš€ Como Usar

### 1. Instalar DependÃªncias

```bash
cd deep_learning
pip install -r requirements-dl.txt
```

**DependÃªncias principais:**
- PyTorch 2.0+ (com suporte MPS para Apple Silicon)
- segmentation-models-pytorch
- albumentations (augmentation)
- tensorboard

### 2. Treinar Modelos

#### **U-Net (Baseline DL)**

```bash
python train.py --model unet --experiment-name unet_baseline
```

#### **Attention U-Net**

```bash
python train.py --model manet --experiment-name attention_unet
```

#### **U-Net++**

```bash
python train.py --model unetplusplus --experiment-name unet_plusplus
```

#### **OpÃ§Ãµes AvanÃ§adas**

```bash
# Treinar com encoder diferente
python train.py --encoder resnet50

# Treinar por mais epochs
python train.py --epochs 100

# Treinar sem pesos prÃ©-treinados
python train.py --encoder-weights None

# Desabilitar augmentation
python train.py --no-augmentation

# Usar loss diferente
python train.py --loss dice
python train.py --loss focal

# Ajustar batch size
python train.py --batch-size 16
```

### 3. Monitorar Treinamento (TensorBoard)

```bash
# Em outro terminal
tensorboard --logdir=runs

# Acessar: http://localhost:6006
```

**TensorBoard mostra:**
- Loss curves (train/val)
- MÃ©tricas (Dice, IoU, Precision, Recall)
- Learning rate decay
- Exemplos de prediÃ§Ãµes (a cada N epochs)

### 4. Avaliar no Test Set

```bash
python evaluate.py --checkpoint checkpoints/unet_baseline/best.pth
```

**Output:**
```
=============================================================
Resultados no Test Set
=============================================================
DICE: 0.7245
IOU: 0.6312
PRECISION: 0.7834
RECALL: 0.7156
=============================================================
```

### 5. Visualizar PrediÃ§Ãµes

```bash
python visualize_predictions.py \
    --checkpoint checkpoints/unet_baseline/best.pth \
    --num-samples 20
```

Gera visualizaÃ§Ãµes comparativas:
- **Imagem Original**
- **Ground Truth** (radiologistas)
- **PrediÃ§Ã£o** (modelo DL)

### 6. Comparar DL vs ClÃ¡ssico

```bash
python compare_models.py
```

Gera tabela comparativa:

| MÃ©todo | Dice Score | IoU | Melhoria vs Baseline |
|--------|------------|-----|----------------------|
| Baseline ClÃ¡ssico | 0.013 | 0.007 | - |
| Otimizado ClÃ¡ssico | 0.023 | 0.012 | +77% |
| **U-Net** | **0.724** | **0.631** | **+5462%** |
| **Attention U-Net** | **0.768** | **0.672** | **+5800%** |
| **U-Net++** | **0.801** | **0.705** | **+6054%** |

---

## âš™ï¸ ConfiguraÃ§Ãµes TÃ©cnicas

### OtimizaÃ§Ãµes para Apple Silicon (M2)

```python
# src/config.py

# Device detection automÃ¡tico
DEVICE = 'mps'  # Metal Performance Shaders

# Mixed precision training (economiza memÃ³ria)
USE_MIXED_PRECISION = True  # FP16

# Gradient clipping (evita exploding gradients)
GRADIENT_CLIP_VAL = 1.0

# Batch size adaptado para 16GB RAM
BATCH_SIZE = 8

# DataLoader workers
NUM_WORKERS = 4
```

### Transfer Learning

**Encoders prÃ©-treinados disponÃ­veis:**
- ResNet: resnet18, resnet34, resnet50, resnet101
- EfficientNet: efficientnet-b0 atÃ© b7
- ResNeXt: resnext50_32x4d, resnext101_32x8d
- DenseNet: densenet121, densenet169
- MobileNet: mobilenet_v2

**Vantagens:**
- ConvergÃªncia mais rÃ¡pida (5-10x)
- Melhor generalizaÃ§Ã£o com dados limitados
- Menor risco de overfitting

---

## ğŸ“Š Experimentos Sugeridos

### 1. ComparaÃ§Ã£o de Arquiteturas

```bash
python train.py --model unet --experiment-name exp1_unet
python train.py --model manet --experiment-name exp2_attention
python train.py --model unetplusplus --experiment-name exp3_unetpp
```

### 2. ComparaÃ§Ã£o de Encoders

```bash
python train.py --encoder resnet34 --experiment-name enc1_resnet34
python train.py --encoder resnet50 --experiment-name enc2_resnet50
python train.py --encoder efficientnet-b3 --experiment-name enc3_effnet
```

### 3. Ablation Study (Augmentation)

```bash
python train.py --experiment-name ablation_with_aug
python train.py --no-augmentation --experiment-name ablation_no_aug
```

### 4. Loss Function Comparison

```bash
python train.py --loss dice --experiment-name loss1_dice
python train.py --loss bce --experiment-name loss2_bce
python train.py --loss focal --experiment-name loss3_focal
python train.py --loss combined --experiment-name loss4_combined
```

---

## ğŸ” Debugging e Troubleshooting

### Treinamento muito lento?

- âœ… Reduzir `BATCH_SIZE` para 4
- âœ… Reduzir `NUM_WORKERS` para 2
- âœ… Usar encoder menor: `--encoder resnet18`
- âœ… Desabilitar augmentation temporariamente

### Out of Memory?

- âœ… Reduzir `BATCH_SIZE` para 4
- âœ… Usar encoder menor: `--encoder resnet18`
- âœ… Desabilitar mixed precision: `USE_MIXED_PRECISION = False`

### Modelo nÃ£o converge?

- âœ… Verificar learning rate (tentar 1e-3 ou 1e-5)
- âœ… Verificar se loss estÃ¡ calculada corretamente
- âœ… Adicionar gradient clipping se muito instÃ¡vel
- âœ… Verificar se masks estÃ£o no range correto [0, 1]

### Overfitting?

- âœ… Aumentar augmentation intensity
- âœ… Aumentar weight decay
- âœ… Reduzir nÃºmero de epochs
- âœ… Usar early stopping (jÃ¡ habilitado por padrÃ£o)

---

## ğŸ¯ Resultados Esperados vs Obtidos

### Benchmarks da Literatura (LIDC-IDRI)

| MÃ©todo | Dice Score (Literatura) | Dice Score (Nosso) |
|--------|-------------------------|---------------------|
| U-Net | 0.70-0.75 | *Em branco* |
| Attention U-Net | 0.73-0.80 | *Em branco* |
| U-Net++ | 0.75-0.85 | *Em branco* |

**Status:** ğŸ”„ **Treinamento pendente** - Execute `train.py` para gerar resultados

---

## ğŸ“š ReferÃªncias

### Arquiteturas

- **U-Net**: Ronneberger et al. "U-Net: Convolutional Networks for Biomedical Image Segmentation" (2015)
- **Attention U-Net**: Oktay et al. "Attention U-Net: Learning Where to Look for the Pancreas" (2018)
- **U-Net++**: Zhou et al. "UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation" (2019)

### Dataset

- **LIDC-IDRI**: Armato III et al. "The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI)" (2011)

### Frameworks

- **PyTorch**: Paszke et al. "PyTorch: An Imperative Style, High-Performance Deep Learning Library" (2019)
- **segmentation-models-pytorch**: Iakubovskii, Pavel. "Segmentation Models Pytorch" (2019)

---

**Sistema completo de Deep Learning implementado e pronto para treinamento!** ğŸš€

*PrÃ³ximo passo: Executar `python train.py` para iniciar o treinamento e gerar resultados.*
