# PulmoSeg

**SegmentaÃ§Ã£o AutomÃ¡tica de NÃ³dulos Pulmonares: Da VisÃ£o Computacional ClÃ¡ssica ao Deep Learning**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

---

## ğŸ“‹ SumÃ¡rio

- [VisÃ£o Geral](#-visÃ£o-geral)
- [MotivaÃ§Ã£o](#-motivaÃ§Ã£o)
- [Dataset](#-dataset-lidc-idri)
- [Metodologia](#-metodologia)
  - [Fase 1: TÃ©cnicas ClÃ¡ssicas](#fase-1-tÃ©cnicas-clÃ¡ssicas-de-processamento-de-imagens)
  - [Fase 2: Deep Learning](#fase-2-deep-learning)
- [Resultados](#-resultados)
- [InstalaÃ§Ã£o e Uso](#-instalaÃ§Ã£o-e-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [ContribuiÃ§Ãµes](#-contribuiÃ§Ãµes)
- [LicenÃ§a](#-licenÃ§a)
- [Autores](#-autores)
- [ReferÃªncias](#-referÃªncias)

---

## ğŸ”¬ VisÃ£o Geral

**PulmoSeg** Ã© um sistema completo de segmentaÃ§Ã£o automÃ¡tica de nÃ³dulos pulmonares desenvolvido como prova de conceito para avaliar e comparar duas abordagens distintas:

1. **TÃ©cnicas ClÃ¡ssicas** de Processamento de Imagens (CLAHE + Otsu + Morfologia)
2. **Deep Learning** com arquiteturas estado-da-arte (U-Net, Attention U-Net, U-Net++)

O projeto utiliza o dataset **LIDC-IDRI** (Lung Image Database Consortium), que contÃ©m anotaÃ§Ãµes de mÃºltiplos radiologistas para validaÃ§Ã£o rigorosa dos mÃ©todos propostos.

---

## ğŸ’¡ MotivaÃ§Ã£o

### Por que SegmentaÃ§Ã£o de NÃ³dulos Pulmonares?

- **CÃ¢ncer de PulmÃ£o** Ã© a principal causa de morte por cÃ¢ncer no mundo
- **DetecÃ§Ã£o precoce** aumenta significativamente a taxa de sobrevivÃªncia (>70% se detectado no estÃ¡gio I)
- **Radiologistas** precisam analisar centenas de imagens por paciente manualmente
- **SegmentaÃ§Ã£o automÃ¡tica** pode:
  - Reduzir tempo de anÃ¡lise
  - Aumentar consistÃªncia no diagnÃ³stico
  - Auxiliar no planejamento de tratamento
  - Permitir monitoramento quantitativo da evoluÃ§Ã£o

### Por que Comparar TÃ©cnicas ClÃ¡ssicas e Deep Learning?

- **Baseline cientÃ­fico**: Estabelecer performance de mÃ©todos tradicionais
- **Justificar complexidade**: Demonstrar necessidade de Deep Learning
- **Entender limitaÃ§Ãµes**: Identificar onde tÃ©cnicas clÃ¡ssicas falham
- **Educacional**: Mostrar evoluÃ§Ã£o de mÃ©todos na Ã¡rea mÃ©dica

---

## ğŸ—‚ï¸ Dataset: LIDC-IDRI

### CaracterÃ­sticas

- **1,018 casos** de TC de tÃ³rax
- **AnotaÃ§Ãµes de 4 radiologistas** experientes por nÃ³dulo
- **~2,600 nÃ³dulos** anotados
- **Fatias 2D** extraÃ­das de volumes 3D
- **Formato**: PNG (512Ã—512 pixels)

### Estrutura

```
LIDC-IDRI-slices/
â””â”€â”€ LIDC-IDRI-XXXX/          # ID do Paciente (874 pacientes)
    â””â”€â”€ nodule-Y/             # ID do NÃ³dulo
        â”œâ”€â”€ images/           # Fatias da TC
        â”‚   â”œâ”€â”€ slice-0.png
        â”‚   â”œâ”€â”€ slice-1.png
        â”‚   â””â”€â”€ slice-N.png
        â”œâ”€â”€ mask-0/           # AnotaÃ§Ã£o do Radiologista 1
        â”œâ”€â”€ mask-1/           # AnotaÃ§Ã£o do Radiologista 2
        â”œâ”€â”€ mask-2/           # AnotaÃ§Ã£o do Radiologista 3
        â””â”€â”€ mask-3/           # AnotaÃ§Ã£o do Radiologista 4
```

### Ground Truth

**MÃ¡scara de Consenso**: Um pixel Ã© considerado nÃ³dulo se **â‰¥2 radiologistas concordam**

Essa abordagem:
- Balanceia sensibilidade e especificidade
- Reduz impacto de anotaÃ§Ãµes individuais ruidosas
- Ã‰ amplamente aceita na literatura mÃ©dica

---

## ğŸ”¬ Metodologia

---

## Fase 1: TÃ©cnicas ClÃ¡ssicas de Processamento de Imagens

> ğŸ“ **CÃ³digo**: `classical_methods/`
>
> ğŸ“– **DocumentaÃ§Ã£o completa**: [classical_methods/README.md](classical_methods/README.md)

### Pipeline BÃ¡sico

```
Imagem TC â†’ Grayscale â†’ CLAHE â†’ Otsu â†’ Morfologia â†’ MÃ¡scara BinÃ¡ria
```

**Etapas detalhadas:**

1. **AquisiÃ§Ã£o e ConversÃ£o**
   - Carregamento da imagem em escala de cinza (8-bit)

2. **Realce de Contraste (CLAHE)**
   - **Algoritmo**: Contrast Limited Adaptive Histogram Equalization
   - **ParÃ¢metros**: `clipLimit=2.0`, `tileGridSize=(8,8)`
   - **Objetivo**: Melhorar contraste local em TCs de baixo contraste

3. **SegmentaÃ§Ã£o (LimiarizaÃ§Ã£o de Otsu)**
   - **Algoritmo**: Threshold automÃ¡tico baseado em histograma
   - **Objetivo**: Separar nÃ³dulo do fundo e tecido pulmonar

4. **OperaÃ§Ãµes MorfolÃ³gicas**
   - **Algoritmo**: Abertura (erosÃ£o + dilataÃ§Ã£o)
   - **Kernel**: ElÃ­ptico 3Ã—3
   - **Objetivo**: Remover ruÃ­do e pequenas estruturas espÃºrias

5. **ExtraÃ§Ã£o de Atributos**
   - CÃ¡lculo da Ã¡rea do nÃ³dulo segmentado (nÃºmero de pixels)

### OtimizaÃ§Ã£o SistemÃ¡tica

Para encontrar a melhor combinaÃ§Ã£o de parÃ¢metros, implementamos **Grid Search** testando:

| Componente | Valores Testados | Total |
|------------|------------------|-------|
| CLAHE clipLimit | 1.0, 2.0, 3.0, 4.0 | 4 |
| CLAHE tileGridSize | (4,4), (8,8), (16,16) | 3 |
| Threshold | Otsu, Adaptive, Binary | 3 |
| Morfologia | Abertura, Fechamento, Gradiente | 3 |
| Kernel Size | 3Ã—3, 5Ã—5, 7Ã—7 | 3 |
| PrÃ©-processamento | None, Gaussian, Median, Bilateral | 4 |

**Total**: **31 configuraÃ§Ãµes** testadas

### EstratÃ©gia de Testes

- **Amostragem**: 10 pacientes (seed=42 para reprodutibilidade)
- **Slices processadas**: 3,565 (115 slices Ã— 31 configuraÃ§Ãµes)
- **MÃ©tricas**: Dice Coefficient e IoU
- **ValidaÃ§Ã£o**: ComparaÃ§Ã£o contra mÃ¡scara de consenso
- **VisualizaÃ§Ã£o**: Top 5 e Bottom 5 casos por configuraÃ§Ã£o
- **Tempo de execuÃ§Ã£o**: ~45 segundos

### Resultados - Fase 1

#### Melhor ConfiguraÃ§Ã£o: `morph_gradient_k5`

**ParÃ¢metros otimizados:**
```json
{
  "clip_limit": 2.0,
  "tile_grid_size": [8, 8],
  "preprocessing": null,
  "threshold_method": "otsu",
  "morph_operation": "gradient",
  "morph_kernel_size": 5
}
```

**Performance:**

| MÃ©trica | Baseline | Otimizado | Melhoria |
|---------|----------|-----------|----------|
| **Dice Score** | 0.0131 Â± 0.0160 | **0.0233 Â± 0.0294** | **+78.26%** |
| **IoU** | 0.0066 Â± 0.0082 | **0.0120 Â± 0.0155** | **+81.82%** |

#### Top 5 ConfiguraÃ§Ãµes

| Rank | ConfiguraÃ§Ã£o | Dice Score | Insight Principal |
|------|--------------|------------|-------------------|
| 1ï¸âƒ£ | morph_gradient_k5 | 0.0233 Â± 0.0294 | **Gradiente morfolÃ³gico** superior a abertura/fechamento |
| 2ï¸âƒ£ | morph_gradient_k3 | 0.0228 Â± 0.0334 | Kernel 3Ã—3 vs 5Ã—5 tem performance similar |
| 3ï¸âƒ£ | morph_gradient_k7 | 0.0220 Â± 0.0259 | Kernel maior nÃ£o melhora significativamente |
| 4ï¸âƒ£ | threshold_adaptive | 0.0191 Â± 0.0171 | **Adaptive threshold** superior a Otsu |
| 5ï¸âƒ£ | clahe_clip4.0_tile8x8 | 0.0173 Â± 0.0178 | CLAHE forte melhora detecÃ§Ã£o de bordas |

#### Insights Principais

âœ… **O que funcionou:**
- **Gradiente MorfolÃ³gico** foi a mudanÃ§a mais impactante (+78% melhoria)
- **Adaptive Threshold** superou Otsu tradicional
- **CLAHE com clip=4.0** melhorou detecÃ§Ã£o de bordas

âŒ **O que nÃ£o funcionou:**
- **PrÃ©-processamento adicional** (Gaussian/Median/Bilateral) nÃ£o melhorou
- **Kernels grandes** (7Ã—7) nÃ£o trouxeram benefÃ­cios
- **Fechamento morfolÃ³gico** teve performance inferior

#### LimitaÃ§Ãµes Identificadas

1. **Scores muito baixos** (~2.3% Dice): Mesmo otimizado, desempenho insuficiente para uso clÃ­nico
2. **Alto desvio padrÃ£o**: Resultados muito variÃ¡veis entre slices
3. **Falhas em baixo contraste**: MÃ©todo falha quando nÃ³dulo tem intensidade similar ao tecido
4. **MÃºltiplas estruturas**: NÃ£o diferencia nÃ³dulo de vasos sanguÃ­neos e outras estruturas
5. **Sem contexto**: Processa cada slice independentemente (sem informaÃ§Ã£o 3D)

**ConclusÃ£o da Fase 1**: TÃ©cnicas clÃ¡ssicas estabelecem baseline, mas performance inadequada justifica necessidade de Deep Learning.

---

## Fase 2: Deep Learning

> ğŸ“ **CÃ³digo**: `deep_learning/`
>
> ğŸ“– **DocumentaÃ§Ã£o completa**: [deep_learning/README.md](deep_learning/README.md)

### Arquiteturas Implementadas

#### 1. **U-Net 2D** (Baseline DL)

**CaracterÃ­sticas:**
- Arquitetura encoder-decoder com skip connections
- Encoder: ResNet34 prÃ©-treinado (ImageNet)
- Decoder: Upsampling com concatenaÃ§Ã£o de features
- **Total de parÃ¢metros**: ~24M

**Por que U-Net?**
- PadrÃ£o-ouro para segmentaÃ§Ã£o mÃ©dica
- Skip connections preservam detalhes espaciais
- Transfer learning acelera convergÃªncia

#### 2. **Attention U-Net** (MAnet)

**CaracterÃ­sticas:**
- Attention gates nas skip connections
- SupressÃ£o de features irrelevantes
- Foco automÃ¡tico em regiÃµes de interesse
- **Total de parÃ¢metros**: ~26M

**Vantagem:**
- Aprende onde focar automaticamente
- Reduz impacto de artefatos e ruÃ­do

#### 3. **U-Net++**

**CaracterÃ­sticas:**
- Nested e dense skip connections
- Sub-redes em mÃºltiplas profundidades
- Ensemble implÃ­cito de U-Nets
- **Total de parÃ¢metros**: ~32M

**Vantagem:**
- Estado-da-arte em segmentaÃ§Ã£o mÃ©dica
- Melhor propagaÃ§Ã£o de gradientes

### Pipeline de Treinamento

#### Split do Dataset

- **70% Treino** (~600 pacientes, ~2000 slices)
- **15% ValidaÃ§Ã£o** (~130 pacientes, ~400 slices)
- **15% Teste** (~130 pacientes, ~400 slices)

**Importante**: Split por **pacientes**, nÃ£o por slices (evita data leakage)

#### Data Augmentation

Pipeline conservador para imagens mÃ©dicas:

| TransformaÃ§Ã£o | ParÃ¢metros | Prob. |
|---------------|------------|-------|
| RotaÃ§Ã£o | Â±15Â° | 70% |
| Flip H/V | - | 50% |
| Escala | 0.9-1.1 | 70% |
| Brilho/Contraste | Â±20% | 50% |
| Elastic Deformation | Î±=50, Ïƒ=8 | 30% |
| Grid Distortion | - | 20% |
| Optical Distortion | - | 20% |

#### Loss Function

**Combined Loss**: `0.5 Ã— Dice Loss + 0.5 Ã— Binary Cross-Entropy`

**Justificativa:**
- **Dice Loss**: Foca em sobreposiÃ§Ã£o (similar Ã  mÃ©trica de avaliaÃ§Ã£o)
- **BCE**: Penaliza prediÃ§Ãµes pixel-a-pixel
- **CombinaÃ§Ã£o**: Balanceia sensibilidade regional e precisÃ£o local

#### Otimizador e Scheduler

- **Optimizer**: AdamW (lr=1e-4, weight_decay=1e-5)
- **Scheduler**: ReduceLROnPlateau (patience=5, factor=0.5)
- **Early Stopping**: Patience=15 epochs
- **Gradient Clipping**: max_norm=1.0

#### ConfiguraÃ§Ãµes TÃ©cnicas

```python
BATCH_SIZE = 8              # Otimizado para M2 16GB RAM
NUM_EPOCHS = 50
LEARNING_RATE = 1e-4
DEVICE = 'mps'              # Metal Performance Shaders (Apple Silicon)
USE_MIXED_PRECISION = True  # FP16 para economizar memÃ³ria
GRADIENT_CLIP_VAL = 1.0
NUM_WORKERS = 4
```

### Resultados - Fase 2

> âš ï¸ **Status**: ğŸ”„ **Treinamento pendente** - Resultados serÃ£o adicionados apÃ³s execuÃ§Ã£o

#### Resultados Esperados (Baseados em Literatura)

| Modelo | Dice Score Esperado | IoU Esperado | Melhoria vs ClÃ¡ssico |
|--------|---------------------|--------------|----------------------|
| Baseline ClÃ¡ssico | 0.013 | 0.007 | - |
| Otimizado ClÃ¡ssico | 0.023 | 0.012 | +77% |
| **U-Net** | **0.70-0.75** | **0.60-0.65** | **+5285%** |
| **Attention U-Net** | **0.73-0.80** | **0.63-0.70** | **+5515%** |
| **U-Net++** | **0.75-0.85** | **0.65-0.75** | **+5670%** |

#### Resultados Obtidos

*SeÃ§Ã£o serÃ¡ preenchida apÃ³s treinamento dos modelos*

**Para gerar resultados:**
```bash
cd deep_learning
python train.py --model unet --experiment-name unet_baseline
python train.py --model manet --experiment-name attention_unet
python train.py --model unetplusplus --experiment-name unet_plusplus
```

---

## ğŸ“Š ComparaÃ§Ã£o Final: ClÃ¡ssico vs Deep Learning

### Performance por MÃ©todo

| Rank | MÃ©todo | Tipo | Dice Score | IoU | Tempo Inf. |
|------|--------|------|------------|-----|------------|
| ğŸ¥‰ | Baseline (Otsu) | ClÃ¡ssico | 0.0131 | 0.0066 | ~10ms |
| ğŸ¥ˆ | Otimizado (Gradient) | ClÃ¡ssico | 0.0233 | 0.0120 | ~15ms |
| ğŸ¥‡ | **U-Net** | **DL** | **~0.72** | **~0.62** | **~50ms** |
| ğŸ¥‡ | **Attention U-Net** | **DL** | **~0.76** | **~0.67** | **~60ms** |
| ğŸ¥‡ | **U-Net++** | **DL** | **~0.80** | **~0.71** | **~70ms** |

*(Valores DL sÃ£o estimativas baseadas em literatura - serÃ£o atualizados apÃ³s treinamento)*

### Trade-offs

#### TÃ©cnicas ClÃ¡ssicas
**Vantagens:**
- âœ… Extremamente rÃ¡pidas (~10-15ms por slice)
- âœ… Sem necessidade de GPU
- âœ… InterpretÃ¡veis (cada etapa Ã© compreensÃ­vel)
- âœ… Sem necessidade de dados de treinamento

**Desvantagens:**
- âŒ Performance insuficiente para uso clÃ­nico
- âŒ SensÃ­vel a variaÃ§Ãµes de contraste e ruÃ­do
- âŒ NÃ£o aprende com dados
- âŒ Requer ajuste manual de parÃ¢metros

#### Deep Learning
**Vantagens:**
- âœ… Performance prÃ³xima de especialistas humanos
- âœ… Aprende automaticamente features relevantes
- âœ… Robusta a variaÃ§Ãµes e ruÃ­do
- âœ… Generaliza bem para novos dados

**Desvantagens:**
- âŒ Requer GPU para treinamento
- âŒ Tempo de treinamento longo (horas)
- âŒ "Black box" (difÃ­cil interpretabilidade)
- âŒ Requer grande volume de dados anotados

---

## ğŸš€ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos

- Python 3.8+
- 16GB RAM recomendado
- GPU NVIDIA (opcional, mas recomendado para DL)
- ou Apple Silicon M1/M2/M3 (suporte MPS)

### InstalaÃ§Ã£o

```bash
# 1. Clonar repositÃ³rio
git clone https://github.com/seu-usuario/Pulmoseg.git
cd Pulmoseg

# 2. Criar ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Instalar dependÃªncias clÃ¡ssicas
cd classical_methods
pip install -r requirements.txt

# 4. Instalar dependÃªncias DL
cd ../deep_learning
pip install -r requirements-dl.txt
```

### Uso RÃ¡pido

#### TÃ©cnicas ClÃ¡ssicas

```bash
cd classical_methods

# Processar 10 pacientes
python main.py --limit 10

# OtimizaÃ§Ã£o completa
python test_optimizer.py --patients 10 --seed 42

# Gerar anÃ¡lises
python analyze_results.py
python report_generator.py
```

#### Deep Learning

```bash
cd deep_learning

# Treinar U-Net
python train.py --model unet

# Treinar Attention U-Net
python train.py --model manet

# Monitorar TensorBoard
tensorboard --logdir=runs

# Avaliar
python evaluate.py --checkpoint checkpoints/unet_resnet34/best.pth

# Visualizar
python visualize_predictions.py --checkpoint checkpoints/unet_resnet34/best.pth
```

---

## ğŸ“‚ Estrutura do Projeto

```
Pulmoseg/
â”‚
â”œâ”€â”€ README.md                        # ğŸ‘ˆ Este arquivo (documentaÃ§Ã£o principal)
â”œâ”€â”€ LICENSE                          # MIT License
â”œâ”€â”€ requirements.txt                 # DependÃªncias compartilhadas
â”‚
â”œâ”€â”€ LIDC-IDRI-slices/               # ğŸ“Š Dataset (nÃ£o versionado)
â”‚   â””â”€â”€ LIDC-IDRI-XXXX/
â”‚       â””â”€â”€ nodule-Y/
â”‚           â”œâ”€â”€ images/
â”‚           â””â”€â”€ mask-{0,1,2,3}/
â”‚
â”œâ”€â”€ classical_methods/              # ğŸ”¬ FASE 1: TÃ©cnicas ClÃ¡ssicas
â”‚   â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o detalhada
â”‚   â”œâ”€â”€ main.py                      # Pipeline base
â”‚   â”œâ”€â”€ pulmoseg_processor.py        # Classe processadora
â”‚   â”œâ”€â”€ test_optimizer.py            # Grid search
â”‚   â”œâ”€â”€ analyze_results.py           # AnÃ¡lise comparativa
â”‚   â”œâ”€â”€ report_generator.py          # GeraÃ§Ã£o de relatÃ³rios
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ results/                     # Resultados gerados
â”‚       â”œâ”€â”€ metrics.csv
â”‚       â”œâ”€â”€ comparison_summary.csv
â”‚       â”œâ”€â”€ best_config.json
â”‚       â”œâ”€â”€ OPTIMIZATION_REPORT.md
â”‚       â””â”€â”€ visualizations/
â”‚
â””â”€â”€ deep_learning/                  # ğŸ§  FASE 2: Deep Learning
    â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o detalhada
    â”œâ”€â”€ train.py                     # Script de treinamento
    â”œâ”€â”€ evaluate.py                  # AvaliaÃ§Ã£o no test set
    â”œâ”€â”€ compare_models.py            # ComparaÃ§Ã£o DL vs ClÃ¡ssico
    â”œâ”€â”€ visualize_predictions.py     # VisualizaÃ§Ã£o
    â”œâ”€â”€ requirements-dl.txt
    â””â”€â”€ src/
        â”œâ”€â”€ config.py                # ConfiguraÃ§Ãµes
        â”œâ”€â”€ dataset.py               # DataLoader
        â”œâ”€â”€ augmentation.py          # Augmentation pipeline
        â”œâ”€â”€ losses.py                # Loss functions
        â”œâ”€â”€ metrics.py               # MÃ©tricas
        â”œâ”€â”€ trainer.py               # Training loop
        â””â”€â”€ models/
            â””â”€â”€ unet.py              # Arquiteturas (U-Net, Attention, U-Net++)
```

---

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ‘¨â€ğŸ’» Autores

**Pericles Feitoza** - *Desenvolvimento e Pesquisa* - [GitHub](https://github.com/seu-usuario)

Desenvolvido como prova de conceito para segmentaÃ§Ã£o de nÃ³dulos pulmonares.

---

## ğŸ“š ReferÃªncias

### Artigos CientÃ­ficos

#### TÃ©cnicas ClÃ¡ssicas
1. **CLAHE**: Zuiderveld, Karel. "Contrast limited adaptive histogram equalization." Graphics gems (1994): 474-485.
2. **Otsu's Method**: Otsu, Nobuyuki. "A threshold selection method from gray-level histograms." IEEE transactions on systems, man, and cybernetics 9.1 (1979): 62-66.

#### Deep Learning
3. **U-Net**: Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. "U-net: Convolutional networks for biomedical image segmentation." International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015.
4. **Attention U-Net**: Oktay, Ozan, et al. "Attention u-net: Learning where to look for the pancreas." arXiv preprint arXiv:1804.03999 (2018).
5. **U-Net++**: Zhou, Zongwei, et al. "Unet++: Redesigning skip connections to exploit multiscale features in image segmentation." IEEE transactions on medical imaging 39.6 (2019): 1856-1867.

### Dataset
6. **LIDC-IDRI**: Armato III, Samuel G., et al. "The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans." Medical physics 38.2 (2011): 915-931.

### Frameworks e Bibliotecas
7. **PyTorch**: Paszke, Adam, et al. "Pytorch: An imperative style, high-performance deep learning library." Advances in neural information processing systems 32 (2019).
8. **Albumentations**: Buslaev, Alexander, et al. "Albumentations: fast and flexible image augmentations." Information 11.2 (2020): 125.
9. **segmentation-models-pytorch**: Iakubovskii, Pavel. "Segmentation Models Pytorch." GitHub repository (2019).

---

## ğŸ¯ PrÃ³ximos Passos

### Melhorias Planejadas

- [ ] **Implementar segmentaÃ§Ã£o 3D**: Processar volumes completos ao invÃ©s de slices 2D
- [ ] **Ensemble de modelos**: Combinar prediÃ§Ãµes de mÃºltiplos modelos
- [ ] **AnÃ¡lise de incerteza**: Quantificar confianÃ§a das prediÃ§Ãµes
- [ ] **Explicabilidade**: Implementar Grad-CAM para visualizar regiÃµes relevantes
- [ ] **Transfer learning avanÃ§ado**: Fine-tuning com dados mÃ©dicos especÃ­ficos
- [ ] **OtimizaÃ§Ã£o de inferÃªncia**: QuantizaÃ§Ã£o e pruning para deployment
- [ ] **Interface web**: Criar interface amigÃ¡vel para uso clÃ­nico
- [ ] **ValidaÃ§Ã£o externa**: Testar em outros datasets (LUNA16, NLST)

### Oportunidades de Pesquisa

- ComparaÃ§Ã£o com mÃ©todos hÃ­bridos (clÃ¡ssico + DL)
- Estudo de generalizaÃ§Ã£o cross-dataset
- AnÃ¡lise de viÃ©s e fairness em diferentes populaÃ§Ãµes
- IntegraÃ§Ã£o com sistemas PACS hospitalares

---

## ğŸ™ Agradecimentos

- **LIDC-IDRI Consortium** pelo dataset pÃºblico
- **PyTorch Team** pelo framework excepcional
- **segmentation-models-pytorch** pela biblioteca de modelos
- **Comunidade open-source** de computer vision mÃ©dica

---

## ğŸ“§ Contato

Para questÃµes, sugestÃµes ou colaboraÃ§Ãµes:

- **Email**: seu-email@example.com
- **GitHub Issues**: [github.com/seu-usuario/Pulmoseg/issues](https://github.com/seu-usuario/Pulmoseg/issues)

---

<div align="center">

**Desenvolvido com â¤ï¸ para avanÃ§ar a segmentaÃ§Ã£o automÃ¡tica de nÃ³dulos pulmonares**

â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!

</div>
